{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc204a60-581a-4e87-8b74-0f6b456aad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"\"\"I’m amazed how often in practice, not only does a @huggingface NLP model solve your problem, but one of their public finetuned checkpoints, is good enough for the job.\n",
    "\n",
    "Both impressed, and a little disappointed how rarely I get to actually train a model that matters :(\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c4527c-9a0f-45f5-9cc1-b975b372d67c",
   "metadata": {},
   "source": [
    "NLTK library for removing stopwords.\n",
    "\n",
    "NLTK comes with several stopword corpora, we will be using the English corpus. This corpus contains a huge number of English stopwords like a, the, be, for, do, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01eb281-d748-4331-b8ee-8bcc5c32f42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "stop_words[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199ce75f-5c23-4bd8-8fd0-ddc7032c4aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i | me | my | myself | we | our | ours | ourselves | you | you're | you've | you'll | you'd | your | yours | yourself | yourselves | he | him | his | himself | she | she's | her | hers | herself | it | it's | its | itself | they | them | their | theirs | themselves | what | which | who | whom | this | that | that'll | these | those | am | is | are | was | were | be | been | being | have | has | had | having | do | does | did | doing | a | an | the | and | but | if | or | because | as | until | while | of | at | by | for | with | about | against | between | into | through | during | before | after | above | below | to | from | up | down | in | out | on | off | over | under | again | further | then | once | here | there | when | where | why | how | all | any | both | each | few | more | most | other | some | such | no | nor | not | only | own | same | so | than | too | very | s | t | can | will | just | don | don't | should | should've | now | d | ll | m | o | re | ve | y | ain | aren | aren't | couldn | couldn't | didn | didn't | doesn | doesn't | hadn | hadn't | hasn | hasn't | haven | haven't | isn | isn't | ma | mightn | mightn't | mustn | mustn't | needn | needn't | shan | shan't | shouldn | shouldn't | wasn | wasn't | weren | weren't | won | won't | wouldn | wouldn't\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" | \".join(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d506e-97c6-4f34-a505-68fe946446b6",
   "metadata": {},
   "source": [
    "Now we have a list of stopwords. When we process our text data we will iterate through each word, if it is present in stop_words it will be removed. To optimize the speed of the stopword lookup we can convert stop_words to a set object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa67a6b-ccf2-4fa9-90b9-44f8499fddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c0b7e6-dd69-4cf9-9e16-3a3936f16c71",
   "metadata": {},
   "source": [
    "First we need to lowercase our text (because all of our stopwords are lowercased). Then we use split our input text into a list of tokens (each token is a word seperated by a space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00394ca7-fcdc-49d5-b37e-6fbb68d77a3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i’m',\n",
       " 'amazed',\n",
       " 'how',\n",
       " 'often',\n",
       " 'in',\n",
       " 'practice,',\n",
       " 'not',\n",
       " 'only',\n",
       " 'does',\n",
       " 'a',\n",
       " '@huggingface',\n",
       " 'nlp',\n",
       " 'model',\n",
       " 'solve',\n",
       " 'your',\n",
       " 'problem,',\n",
       " 'but',\n",
       " 'one',\n",
       " 'of',\n",
       " 'their',\n",
       " 'public',\n",
       " 'finetuned',\n",
       " 'checkpoints,',\n",
       " 'is',\n",
       " 'good',\n",
       " 'enough',\n",
       " 'for',\n",
       " 'the',\n",
       " 'job.',\n",
       " 'both',\n",
       " 'impressed,',\n",
       " 'and',\n",
       " 'a',\n",
       " 'little',\n",
       " 'disappointed',\n",
       " 'how',\n",
       " 'rarely',\n",
       " 'i',\n",
       " 'get',\n",
       " 'to',\n",
       " 'actually',\n",
       " 'train',\n",
       " 'a',\n",
       " 'model',\n",
       " 'that',\n",
       " 'matters',\n",
       " ':(']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = tweet.lower().split() # lower() for lowercase and split() for splitting on space character as delimiter\n",
    "\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92ce315-88d6-4253-9e15-4a9aa833393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With stopwords: i’m amazed how often in practice, not only does a @huggingface nlp model solve your problem, but one of their public finetuned checkpoints, is good enough for the job. both impressed, and a little disappointed how rarely i get to actually train a model that matters :(\n"
     ]
    }
   ],
   "source": [
    "tweet_no_stopwords = [word for word in tweet if word not in stop_words]\n",
    "\n",
    "print(\"With stopwords:\", ' '.join(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9d2ff52-831e-4b8b-9e31-afef5bd8e8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without stopwords: i’m amazed often practice, @huggingface nlp model solve problem, one public finetuned checkpoints, good enough job. impressed, little disappointed rarely get actually train model matters :(\n"
     ]
    }
   ],
   "source": [
    "print(\"Without stopwords:\", ' '.join(tweet_no_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df96f9c-cfc4-4546-9c9a-5066f8818680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
