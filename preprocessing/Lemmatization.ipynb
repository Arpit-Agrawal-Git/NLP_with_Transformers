{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9a7f18-a1bd-42cc-8015-80dbd6e153b2",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "Lemmatization is very similiar to stemming in that it reduces a set of inflected words down to a common word. The difference is that lemmatization reduces inflections down to their real root words, which is called a lemma. If we take the words 'amaze', 'amazing', 'amazingly', the lemma of all of these is 'amaze'. Compared to stemming which would usually return 'amaz'. Generally lemmatization is seen as more advanced than stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052368fe-71f6-490f-9ede-ec6245f91a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['amaze', 'amazed', 'amazing']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513590e8-f0e6-4bdd-a7b1-944f445a64af",
   "metadata": {},
   "source": [
    "We will use NLTK again for our lemmatization. We also need to ensure we have the WordNet Database downloaded which will act as the lookup for our lemmatizer to ensure that it has produced a real lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fdc58a0-e68d-467b-92bf-d569b6a89ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\arpit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['amaze', 'amazed', 'amazing']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "[lemmatizer.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b501e06-5f35-4b5c-87c3-a1e01ec7966b",
   "metadata": {},
   "source": [
    "Clearly nothing has happened, and that is because lemmatization requires that we also provide the **parts-of-speech (POS) tag**, which is the category of a word based on syntax. For example noun, adjective, or verb. In our case we could place each word as a verb, which we can then implement like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c3193f-19d0-4952-b892-9e59fe3a7592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amaze', 'amaze', 'amaze']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "[lemmatizer.lemmatize(word, wordnet.VERB) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a630b-83e9-41dc-a1ea-0ea368879af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502ed1c-5929-4409-a44e-f1fbd6a23832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
